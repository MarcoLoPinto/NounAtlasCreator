{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will add the missing roles in the temporary NoUniteD dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe2040e",
   "metadata": {
    "papermill": {
     "duration": 0.078963,
     "end_time": "2022-03-31T22:14:09.386664",
     "exception": false,
     "start_time": "2022-03-31T22:14:09.307701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/miniconda3/envs/nuans_minihw2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5424a631",
   "metadata": {
    "papermill": {
     "duration": 0.049244,
     "end_time": "2022-03-31T22:14:12.552634",
     "exception": false,
     "start_time": "2022-03-31T22:14:12.503390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Important paths for the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_root_path = './temp_files/'\n",
    "srl_dataset_path = os.path.join(datasets_root_path, 'maven_nounited_srl')\n",
    "checkpoints_dir_path = './checkpoints/'\n",
    "model_dir_path = os.path.join(checkpoints_dir_path, 'models_nounited_maven')\n",
    "\n",
    "srl_dataset_dict_paths = {}\n",
    "for lang in os.listdir(srl_dataset_path):\n",
    "    dataset_lang_path = os.path.join(srl_dataset_path, lang)\n",
    "    if os.path.isdir(dataset_lang_path):\n",
    "        srl_dataset_dict_paths[lang] = {}\n",
    "        for d_type in os.listdir(dataset_lang_path):\n",
    "            d_name = d_type.split('.')[0]\n",
    "            srl_dataset_dict_paths[lang][d_name] = os.path.join(dataset_lang_path, d_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc95ee",
   "metadata": {
    "papermill": {
     "duration": 0.048851,
     "end_time": "2022-03-31T22:14:13.015246",
     "exception": false,
     "start_time": "2022-03-31T22:14:12.966395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Setting the seed for reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 28\n",
    "\n",
    "# random.seed(SEED) # not used\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_params = np.load(os.path.join(model_dir_path, 'global_params.npy'), allow_pickle=True).tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding final roles to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code_files.datasets.dataset_nounited import DatasetNoUniteD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_type = '_n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_en_aic = DatasetNoUniteD(  srl_dataset_dict_paths['EN']['train'], split_predicates=True, split_type_to_use = split_type )\n",
    "dataset_dev_en_aic = DatasetNoUniteD(  srl_dataset_dict_paths['EN']['dev'], split_predicates=True, split_type_to_use = split_type )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words': ['The',\n",
       "  '2006',\n",
       "  'Pangandaran',\n",
       "  'earthquake',\n",
       "  'and',\n",
       "  'tsunami',\n",
       "  'occurred',\n",
       "  'on',\n",
       "  'July',\n",
       "  '17',\n",
       "  'at',\n",
       "  'along',\n",
       "  'a',\n",
       "  'subduction',\n",
       "  'zone',\n",
       "  'off',\n",
       "  'the',\n",
       "  'coast',\n",
       "  'of',\n",
       "  'west',\n",
       "  'and',\n",
       "  'central',\n",
       "  'Java',\n",
       "  ',',\n",
       "  'a',\n",
       "  'large',\n",
       "  'and',\n",
       "  'densely',\n",
       "  'populated',\n",
       "  'island',\n",
       "  'in',\n",
       "  'the',\n",
       "  'Indonesian',\n",
       "  'archipelago',\n",
       "  '.'],\n",
       " 'predicates': ['_',\n",
       "  '_',\n",
       "  '_',\n",
       "  'MOVE-ONESELF',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_'],\n",
       " 'predicates_v': ['_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  'HAPPEN_OCCUR',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_'],\n",
       " 'predicates_n': ['_',\n",
       "  '_',\n",
       "  '_',\n",
       "  'MOVE-ONESELF',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_'],\n",
       " 'roles': [],\n",
       " 'roles_v': {'6': ['_',\n",
       "   '_',\n",
       "   '_',\n",
       "   'theme',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_']},\n",
       " 'roles_n': {},\n",
       " 'num_v': 1,\n",
       " 'num_n': 1,\n",
       " 'lemmas': ['the',\n",
       "  '2006',\n",
       "  'Pangandaran',\n",
       "  'earthquake',\n",
       "  'and',\n",
       "  'tsunami',\n",
       "  'occur',\n",
       "  'on',\n",
       "  'July',\n",
       "  '17',\n",
       "  'at',\n",
       "  'along',\n",
       "  'a',\n",
       "  'subduction',\n",
       "  'zone',\n",
       "  'off',\n",
       "  'the',\n",
       "  'coast',\n",
       "  'of',\n",
       "  'west',\n",
       "  'and',\n",
       "  'central',\n",
       "  'Java',\n",
       "  ',',\n",
       "  'a',\n",
       "  'large',\n",
       "  'and',\n",
       "  'densely',\n",
       "  'populate',\n",
       "  'island',\n",
       "  'in',\n",
       "  'the',\n",
       "  'Indonesian',\n",
       "  'archipelago',\n",
       "  '.'],\n",
       " 'pos_tags': ['DET',\n",
       "  'NUM',\n",
       "  'PROPN',\n",
       "  'NOUN',\n",
       "  'CCONJ',\n",
       "  'NOUN',\n",
       "  'VERB',\n",
       "  'ADP',\n",
       "  'PROPN',\n",
       "  'NUM',\n",
       "  'ADP',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'PROPN',\n",
       "  'CCONJ',\n",
       "  'ADJ',\n",
       "  'PROPN',\n",
       "  'PUNCT',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'CCONJ',\n",
       "  'ADV',\n",
       "  'VERB',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'PUNCT'],\n",
       " 'dependency_heads': [4,\n",
       "  4,\n",
       "  4,\n",
       "  7,\n",
       "  6,\n",
       "  4,\n",
       "  0,\n",
       "  10,\n",
       "  10,\n",
       "  7,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  7,\n",
       "  18,\n",
       "  18,\n",
       "  15,\n",
       "  20,\n",
       "  18,\n",
       "  23,\n",
       "  23,\n",
       "  20,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  29,\n",
       "  29,\n",
       "  26,\n",
       "  18,\n",
       "  34,\n",
       "  34,\n",
       "  34,\n",
       "  30,\n",
       "  7],\n",
       " 'dependency_relations': ['det',\n",
       "  'compound',\n",
       "  'compound',\n",
       "  'nsubj',\n",
       "  'cc',\n",
       "  'conj',\n",
       "  'root',\n",
       "  'case',\n",
       "  'compound',\n",
       "  'obl',\n",
       "  'case',\n",
       "  'case',\n",
       "  'det',\n",
       "  'compound',\n",
       "  'obl',\n",
       "  'case',\n",
       "  'det',\n",
       "  'nmod',\n",
       "  'case',\n",
       "  'nmod',\n",
       "  'cc',\n",
       "  'amod',\n",
       "  'conj',\n",
       "  'punct',\n",
       "  'det',\n",
       "  'amod',\n",
       "  'cc',\n",
       "  'advmod',\n",
       "  'conj',\n",
       "  'appos',\n",
       "  'case',\n",
       "  'det',\n",
       "  'amod',\n",
       "  'nmod',\n",
       "  'punct'],\n",
       " 'predicate_word': ['earthquake'],\n",
       " 'predicate_name': ['MOVE-ONESELF']}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_en_aic.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from code_files.models.model_aic import ModelAIC\n",
    "model_aic = ModelAIC(hparams = global_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aic.load_weights(os.path.join(model_dir_path, f'aic_transformer_nounited_v.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The July 2006 [earthquake] was also centered in the Indian Ocean , from the coast of Java , and had a duration of more than three minutes .\n",
      "['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n"
     ]
    }
   ],
   "source": [
    "ssmpl = 3\n",
    "samppll = dataset_train_en_aic.data[ssmpl]\n",
    "\n",
    "print(\" \".join([w if samppll['predicate_word'][0] != w else f\"[{w}]\" for w in samppll['words']]))\n",
    "print( model_aic.predict([samppll['words']], [samppll['predicate_word']])[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuans_minihw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8ff4b25b18867855edb86ba2aaa718c4e3e5e5df1f72ad6de2c0263a3e32427"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
