{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Doc as SpacyDoc\n",
    "import json\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.tokenizer=lambda doc: doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/united-srl/EN/dev.json') as json_file:\n",
    "    d = json.load(json_file)\n",
    "d = list(d.values()) if type(d) == dict else d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'urges', 'the', 'Government', 'to', 'take', 'measures', 'to', 'protect', 'persons', 'who', 'have', 'received', 'death', 'threats', '.']\n",
      "[2, 0, 4, 2, 6, 2, 6, 9, 6, 9, 13, 13, 10, 15, 13, 2]\n",
      "['nsubj', 'root', 'det', 'obj', 'mark', 'xcomp', 'obj', 'mark', 'advcl', 'obj', 'nsubj', 'aux', 'acl:relcl', 'compound', 'obj', 'punct']\n",
      "['he', 'urge', 'the', 'government', 'to', 'take', 'measure', 'to', 'protect', 'person', 'who', 'have', 'receive', 'death', 'threat', '.']\n"
     ]
    }
   ],
   "source": [
    "smpl = 4\n",
    "print( d[smpl]['words'] )\n",
    "print( d[smpl]['dependency_heads'] )\n",
    "print( d[smpl]['dependency_relations'] )\n",
    "print( d[smpl]['lemmas'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_result = nlp(SpacyDoc(nlp.vocab, d[smpl]['words']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He nsubj 1 urges PRON he\n",
      "urges ROOT 1 urges VERB urge\n",
      "the det 3 Government DET the\n",
      "Government dobj 1 urges PROPN Government\n",
      "to aux 5 take PART to\n",
      "take xcomp 1 urges VERB take\n",
      "measures dobj 5 take NOUN measure\n",
      "to aux 8 protect PART to\n",
      "protect relcl 6 measures VERB protect\n",
      "persons dobj 8 protect NOUN person\n",
      "who nsubj 12 received PRON who\n",
      "have aux 12 received AUX have\n",
      "received relcl 9 persons VERB receive\n",
      "death compound 14 threats NOUN death\n",
      "threats dobj 12 received NOUN threat\n",
      ". punct 1 urges PUNCT .\n"
     ]
    }
   ],
   "source": [
    "for token in spacy_result:\n",
    "    print(token, token.dep_, token.head.i, token.head, token.pos_, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-08 15:11:01 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json: 193kB [00:00, 14.6MB/s]                    \n",
      "2023-01-08 15:11:02 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/pos/combined.pt: 100%|██████████| 38.5M/38.5M [00:15<00:00, 2.52MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/lemma/combined.pt: 100%|██████████| 4.17M/4.17M [00:01<00:00, 2.34MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/depparse/combined.pt: 100%|██████████| 109M/109M [00:42<00:00, 2.60MB/s] \n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/pretrain/combined.pt: 100%|██████████| 107M/107M [00:41<00:00, 2.58MB/s] \n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/backward_charlm/1billion.pt: 100%|██████████| 22.7M/22.7M [00:10<00:00, 2.22MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/forward_charlm/1billion.pt: 100%|██████████| 22.7M/22.7M [00:10<00:00, 2.27MB/s]\n",
      "2023-01-08 15:13:07 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "| depparse  | combined |\n",
      "========================\n",
      "\n",
      "2023-01-08 15:13:07 INFO: Use device: gpu\n",
      "2023-01-08 15:13:07 INFO: Loading: tokenize\n",
      "2023-01-08 15:13:07 INFO: Loading: pos\n",
      "2023-01-08 15:13:10 INFO: Loading: lemma\n",
      "2023-01-08 15:13:10 INFO: Loading: depparse\n",
      "2023-01-08 15:13:10 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "stanza_nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse', tokenize_pretokenized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'urges', 'the', 'Government', 'to', 'take', 'measures', 'to', 'protect', 'persons', 'who', 'have', 'received', 'death', 'threats', '.']\n",
      "[2, 0, 4, 2, 6, 2, 6, 9, 6, 9, 13, 13, 10, 15, 13, 2]\n",
      "['nsubj', 'root', 'det', 'obj', 'mark', 'xcomp', 'obj', 'mark', 'advcl', 'obj', 'nsubj', 'aux', 'acl:relcl', 'compound', 'obj', 'punct']\n",
      "['he', 'urge', 'the', 'government', 'to', 'take', 'measure', 'to', 'protect', 'person', 'who', 'have', 'receive', 'death', 'threat', '.']\n",
      "['PRON', 'VERB', 'DET', 'NOUN', 'PART', 'VERB', 'NOUN', 'PART', 'VERB', 'NOUN', 'PRON', 'AUX', 'VERB', 'NOUN', 'NOUN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "smpl = 4\n",
    "print( d[smpl]['words'] )\n",
    "print( d[smpl]['dependency_heads'] )\n",
    "print( d[smpl]['dependency_relations'] )\n",
    "print( d[smpl]['lemmas'] )\n",
    "print( d[smpl]['pos_tags'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = stanza_nlp([d[smpl]['words']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc.sentences[0].words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 4, 2, 6, 2, 6, 9, 6, 9, 13, 13, 10, 15, 13, 2]\n",
      "['nsubj', 'root', 'det', 'obj', 'mark', 'xcomp', 'obj', 'mark', 'advcl', 'obj', 'nsubj', 'aux', 'acl:relcl', 'compound', 'obj', 'punct']\n",
      "['PRON', 'VERB', 'DET', 'NOUN', 'PART', 'VERB', 'NOUN', 'PART', 'VERB', 'NOUN', 'PRON', 'AUX', 'VERB', 'NOUN', 'NOUN', 'PUNCT']\n",
      "['he', 'urge', 'the', 'government', 'to', 'take', 'measure', 'to', 'protect', 'person', 'who', 'have', 'receive', 'death', 'threat', '.']\n"
     ]
    }
   ],
   "source": [
    "print([word.head for word in doc.sentences[0].words])\n",
    "print([word.deprel for word in doc.sentences[0].words])\n",
    "print([word.upos for word in doc.sentences[0].words])\n",
    "print([word.lemma for word in doc.sentences[0].words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: He\thead id: 2\thead: urges\tdeprel: nsubj\n",
      "id: 2\tword: urges\thead id: 0\thead: root\tdeprel: root\n",
      "id: 3\tword: the\thead id: 4\thead: Government\tdeprel: det\n",
      "id: 4\tword: Government\thead id: 2\thead: urges\tdeprel: obj\n",
      "id: 5\tword: to\thead id: 6\thead: take\tdeprel: mark\n",
      "id: 6\tword: take\thead id: 2\thead: urges\tdeprel: xcomp\n",
      "id: 7\tword: measures\thead id: 6\thead: take\tdeprel: obj\n",
      "id: 8\tword: to\thead id: 9\thead: protect\tdeprel: mark\n",
      "id: 9\tword: protect\thead id: 6\thead: take\tdeprel: advcl\n",
      "id: 10\tword: persons\thead id: 9\thead: protect\tdeprel: obj\n",
      "id: 11\tword: who\thead id: 13\thead: received\tdeprel: nsubj\n",
      "id: 12\tword: have\thead id: 13\thead: received\tdeprel: aux\n",
      "id: 13\tword: received\thead id: 10\thead: persons\tdeprel: acl:relcl\n",
      "id: 14\tword: death\thead id: 15\thead: threats\tdeprel: compound\n",
      "id: 15\tword: threats\thead id: 13\thead: received\tdeprel: obj\n",
      "id: 16\tword: .\thead id: 2\thead: urges\tdeprel: punct\n"
     ]
    }
   ],
   "source": [
    "print(*[f'id: {word.id}\\tword: {word.text}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuans_minihw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8ff4b25b18867855edb86ba2aaa718c4e3e5e5df1f72ad6de2c0263a3e32427"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
